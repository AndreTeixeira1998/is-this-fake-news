{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"/kaggle/input/fake-and-real-news-dataset/True.csv\n/kaggle/input/fake-and-real-news-dataset/Fake.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> ## Import and examine data","metadata":{}},{"cell_type":"code","source":"real_df = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\nfake_df = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')\nreal_df['label'] = 1\nfake_df['label'] = 0\ndf = pd.concat([real_df, fake_df], axis=0, ignore_index=True)","metadata":{"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 44898 entries, 0 to 44897\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   title    44898 non-null  object\n 1   text     44898 non-null  object\n 2   subject  44898 non-null  object\n 3   date     44898 non-null  object\n 4   label    44898 non-null  int64 \ndtypes: int64(1), object(4)\nmemory usage: 1.7+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{}},{"cell_type":"code","source":"import warnings   \nwarnings.filterwarnings(action = 'ignore') \n\nimport re\nfrom string import punctuation\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encode subject","metadata":{}},{"cell_type":"code","source":"#data = pd.get_dummies(df, columns=['subject'])\ndata = df\ndata.drop(['subject'], inplace=True, axis=1)\ndata.drop(['date'], inplace=True, axis=1)\ndata.head()","metadata":{"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text  label  \n0  WASHINGTON (Reuters) - The head of a conservat...      1  \n1  WASHINGTON (Reuters) - Transgender people will...      1  \n2  WASHINGTON (Reuters) - The special counsel inv...      1  \n3  WASHINGTON (Reuters) - Trump campaign adviser ...      1  \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n\ndef preprocess(df):\n    lemmatizer = WordNetLemmatizer()\n\n    text_processed = []\n    for text in df.text:\n        # remove punctuation and lowercase\n        text = re.sub(r'[^a-zA-Z]', ' ', text) \n        text = text.lower()\n        \n        # tokenize and lemmatize tokens\n        tokens = word_tokenize(text)\n        tokens = [lemmatizer.lemmatize(x) for x in tokens]\n        text_processed.append(' '.join(tokens))\n \n\n    title_processed = []\n    for title in df.title:\n        # remove punctuation and lowercase\n        title = re.sub(r'[^a-zA-Z]', ' ', title) \n        title = title.lower()\n        \n        # tokenize and lemmatize tokens\n        tokens = word_tokenize(title)\n        tokens = [lemmatizer.lemmatize(x) for x in tokens]\n        title_processed.append(' '.join(tokens))\n        \n    # vectorize\n    text_vectorizer = CountVectorizer(stop_words='english', max_features=4000)\n    title_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n    text_matrix = text_vectorizer.fit_transform(text_processed).toarray()\n    title_matrix = title_vectorizer.fit_transform(title_processed).toarray()\n    \n    # save vectorizers\n    pickle.dump(text_vectorizer, open('text_vectorizer.pkl','wb'))\n    pickle.dump(title_vectorizer, open('title_vectorizer.pkl','wb'))\n    \n    # store label then drop old text columns and label\n    y = np.array(df.label)\n    df.drop(['title','text','label'], inplace=True, axis=1)\n    \n    # return np matrix\n    X = np.concatenate([title_matrix, text_matrix], axis=1)\n    return X, y","metadata":{"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X, y = preprocess(data)","metadata":{"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(31428, 5000)\n(13470, 5000)\n(31428,)\n(13470,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        \n        # input layer\n        self.l1 = nn.Linear(5000, 2000) # input shape (5008,) -> output to layer 2000 units\n        self.relu1 = nn.ReLU()\n        \n        # hidden layer 1\n        self.l2 = nn.Linear(2000, 500)  # input shape 2000 -> output to layer 1000 units\n        self.relu2 = nn.ReLU()\n        \n        # hidden layer 2\n        self.l3 = nn.Linear(500, 100)    # input shape 500 -> output to layer 100 units\n        self.relu3 = nn.ReLU()\n        \n        # hidden layer 3\n        self.l4 = nn.Linear(100, 20)    # input shape 100 -> output to layer 20 units\n        self.relu4 = nn.ReLU()\n        \n        # output layer\n        self.l5 = nn.Linear(20, 2)      # input shape 20 -> output layer 2 units (binary classifier)\n        \n    def forward(self, X):\n        out = self.l1(X)\n        out = self.relu1(out)\n        \n        out = self.l2(out)\n        out = self.relu2(out)\n        \n        out = self.l3(out)\n        out = self.relu3(out)\n        \n        out = self.l4(out)\n        out = self.relu4(out)\n        \n        out = self.l5(out)\n        return out","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer and loss function","metadata":{}},{"cell_type":"code","source":"model = MLP()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nerror = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"X_train = torch.Tensor(X_train)\ny_train = torch.Tensor(y_train).type(torch.LongTensor)\n\nX_test = torch.Tensor(X_test)\ny_test = torch.Tensor(y_test).type(torch.LongTensor)","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\nfor epoch in range(epochs):\n    \n    # clear gradients\n    optimizer.zero_grad()\n    \n    # forward pass\n    out = model(X_train)\n    \n    # compute loss\n    loss = error(out, y_train)\n    \n    # backprop\n    loss.backward()\n    \n    # update parameters\n    optimizer.step()\n    \n    # print train loss\n    print(f'Epoch {epoch} Loss: {loss}')\n    ","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 0.695485532283783\nEpoch 1 Loss: 0.6704117655754089\nEpoch 2 Loss: 0.5986687541007996\nEpoch 3 Loss: 0.4957452714443207\nEpoch 4 Loss: 0.38455671072006226\nEpoch 5 Loss: 0.27917471528053284\nEpoch 6 Loss: 0.19155257940292358\nEpoch 7 Loss: 0.13460403680801392\nEpoch 8 Loss: 0.12006562948226929\nEpoch 9 Loss: 0.11622913926839828\nEpoch 10 Loss: 0.06967885047197342\nEpoch 11 Loss: 0.08273657411336899\nEpoch 12 Loss: 0.04991612210869789\nEpoch 13 Loss: 0.06637027114629745\nEpoch 14 Loss: 0.03500920534133911\nEpoch 15 Loss: 0.04353638365864754\nEpoch 16 Loss: 0.030849652364850044\nEpoch 17 Loss: 0.02082207426428795\nEpoch 18 Loss: 0.025929506868124008\nEpoch 19 Loss: 0.017286110669374466\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(X_test[0].shape)\n# y_pred = model(torch.Tensor(X_test_single))\n# y_pred_max = torch.max(y_pred,1)[1]\n# print(y_pred_max)\n# test_accuracy = accuracy_score(y_pred_max, y_test)\n# print(f'Test accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"(5000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\npickle.dump(model, open('model.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}